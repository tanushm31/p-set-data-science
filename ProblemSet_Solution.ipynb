{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e673f111",
   "metadata": {},
   "source": [
    "## Importing Relevant Libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a2116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim, spacy\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb708cf",
   "metadata": {},
   "source": [
    "## Importing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e3a3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"D:\\Study\\Supermind\\ds-data\"\n",
    "dfs= []\n",
    "jsons = []\n",
    "for root, subdirectories, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filename = os.path.join(root, file)\n",
    "        f = open(filename)\n",
    "        data = json.load(f)\n",
    "        f.close\n",
    "        jsons.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45acb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = {\n",
    "            \"Serial\":[],\n",
    "            \"Id\":[],\n",
    "            \"Text\":[]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72413019",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(jsons)):\n",
    "    for i in jsons[j]:\n",
    "        chats[\"Serial\"].append(j)\n",
    "        chats[\"Id\"].append(i['id'])\n",
    "        chats[\"Text\"].append(i['text']['text'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea84f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da67f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34134</th>\n",
       "      <td>86</td>\n",
       "      <td>377889</td>\n",
       "      <td>That's unrelated. The question is what the inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34135</th>\n",
       "      <td>86</td>\n",
       "      <td>377888</td>\n",
       "      <td>If you have to pow on the user side then you'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34136</th>\n",
       "      <td>86</td>\n",
       "      <td>377887</td>\n",
       "      <td>there doesn't appear to be any. though if you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34137</th>\n",
       "      <td>86</td>\n",
       "      <td>377886</td>\n",
       "      <td>What is the incentive to validate txs in Nano?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34138</th>\n",
       "      <td>86</td>\n",
       "      <td>377885</td>\n",
       "      <td>I remember first hearing about it when it went...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial      Id                                               Text\n",
       "34134      86  377889  That's unrelated. The question is what the inc...\n",
       "34135      86  377888  If you have to pow on the user side then you'r...\n",
       "34136      86  377887  there doesn't appear to be any. though if you ...\n",
       "34137      86  377886     What is the incentive to validate txs in Nano?\n",
       "34138      86  377885  I remember first hearing about it when it went..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff945e",
   "metadata": {},
   "source": [
    "## Using NLTK for Question Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1045ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd73aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74ea718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package nps_chat to C:\\Users\\TANUSH\n",
      "[nltk_data]     MAHAJAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2b776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n",
    "\n",
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features\n",
    "\n",
    "featuresets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]\n",
    "\n",
    "# 10% of the total data\n",
    "size = int(len(featuresets) * 0.1)\n",
    "\n",
    "# first 10% for test_set to check the accuracy, and rest 90% after the first 10% for training\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "\n",
    "# get the classifer from the training set\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# to check the accuracy - 0.67\n",
    "# print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "question_types = [\"whQuestion\",\"ynQuestion\"]\n",
    "def is_ques_using_nltk(ques):\n",
    "    question_type = classifier.classify(dialogue_act_features(ques)) \n",
    "    return question_type in question_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfd8f9",
   "metadata": {},
   "source": [
    "## Using Sentence Structure To Detect Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f676fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pattern = [\"do i\", \"do you\", \"what\", \"who\", \"is it\", \"why\",\"would you\", \"how\",\"is there\",\n",
    "                    \"are there\", \"is it so\", \"is this true\" ,\"to know\", \"is that true\", \"are we\", \"am i\", \n",
    "                   \"question is\", \"tell me more\", \"can i\", \"can we\", \"tell me\", \"can you explain\",\n",
    "                   \"question\",\"answer\", \"questions\", \"answers\", \"ask\"]\n",
    "\n",
    "helping_verbs = [\"is\",\"am\",\"can\", \"are\", \"do\", \"does\"]\n",
    "# check with custom pipeline if still this is a question mark it as a question\n",
    "def is_question(question):\n",
    "    question = question.lower().strip()\n",
    "    if not is_ques_using_nltk(question):\n",
    "        is_ques = False\n",
    "        # check if any of pattern exist in sentence\n",
    "        for pattern in question_pattern:\n",
    "            is_ques  = pattern in question\n",
    "            if is_ques:\n",
    "                break\n",
    "\n",
    "        # there could be multiple sentences so divide the sentence\n",
    "        sentence_arr = question.split(\".\")\n",
    "        for sentence in sentence_arr:\n",
    "            if len(sentence.strip()):\n",
    "                # if question ends with ? or start with any helping verb\n",
    "                # word_tokenize will strip by default\n",
    "                first_word = nltk.word_tokenize(sentence)[0]\n",
    "                if sentence.endswith(\"?\") or first_word in helping_verbs:\n",
    "                    is_ques = True\n",
    "                    break\n",
    "        return is_ques    \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76432d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_question'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9c1dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_question_using_nltk'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "586214e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>is_question</th>\n",
       "      <th>is_question_using_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>377801</td>\n",
       "      <td>wat is it lmao</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>377800</td>\n",
       "      <td>No risk here platform will be free</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>377799</td>\n",
       "      <td>@lordvladin im more confused after I read your...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>377798</td>\n",
       "      <td>has anyone sold or bought a house using crypto...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>377796</td>\n",
       "      <td>I sent you DM thank you</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial      Id                                               Text  \\\n",
       "0       0  377801                                     wat is it lmao   \n",
       "1       0  377800                 No risk here platform will be free   \n",
       "2       0  377799  @lordvladin im more confused after I read your...   \n",
       "3       0  377798  has anyone sold or bought a house using crypto...   \n",
       "4       0  377796                            I sent you DM thank you   \n",
       "\n",
       "  is_question is_question_using_nltk  \n",
       "0                                     \n",
       "1                                     \n",
       "2                                     \n",
       "3                                     \n",
       "4                                     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89716ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48d02d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 34138/34138 [00:59<00:00, 572.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df)-1)):\n",
    "    if(df['Text'][i]):\n",
    "        df.at[i,'is_question'] = str(is_question(df['Text'][i]))\n",
    "        df.at[i,\"is_question_using_nltk\"] = str(is_ques_using_nltk(df['Text'][i]))   \n",
    "    else:\n",
    "        df.at[i,'is_question'] = \"None\"\n",
    "        df.at[i,\"is_question_using_nltk\"] = \"None\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa808d85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>is_question</th>\n",
       "      <th>is_question_using_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>377801</td>\n",
       "      <td>wat is it lmao</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>377800</td>\n",
       "      <td>No risk here platform will be free</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>377799</td>\n",
       "      <td>@lordvladin im more confused after I read your...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>377798</td>\n",
       "      <td>has anyone sold or bought a house using crypto...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>377796</td>\n",
       "      <td>I sent you DM thank you</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>377795</td>\n",
       "      <td>Can DM me. I'm out rn but will get back by lat...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>377794</td>\n",
       "      <td>Dequest is an sbt2 layer on web3 gamification ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>377793</td>\n",
       "      <td>I think dequest focusing on web3 games, as i s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>377792</td>\n",
       "      <td>but feel free to dm me if using rmrk</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>377791</td>\n",
       "      <td>look into dequest too</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>377790</td>\n",
       "      <td>Also if anyone can share what is the defects o...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>377789</td>\n",
       "      <td>Also i was trying to use remark for NFTs to cr...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>377788</td>\n",
       "      <td>Platform is free to use</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>377787</td>\n",
       "      <td>I can also share the platform here with you if...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>377786</td>\n",
       "      <td>I don’t have connections i am working alone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>377785</td>\n",
       "      <td>So the system is ready just working on the con...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>377784</td>\n",
       "      <td>I'm.messing around but share what you are doing</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>377783</td>\n",
       "      <td>Dude don't mind me</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>377782</td>\n",
       "      <td>Hahaha</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>377781</td>\n",
       "      <td>I am just excited to talk about it</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>377780</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>377779</td>\n",
       "      <td>Other wise working on platform to reward peopl...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>377778</td>\n",
       "      <td>Sir.  Single para. Pls.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>377777</td>\n",
       "      <td>Why working on lame, 2d 90th games</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>377776</td>\n",
       "      <td>Okay single text - what it does.</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>377775</td>\n",
       "      <td>And i got an idea while working</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>377773</td>\n",
       "      <td>No it more simple than this</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>377772</td>\n",
       "      <td>If yes then please speak</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>377771</td>\n",
       "      <td>Is this “IT” a shitcoin, ponzu or other food f...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>377770</td>\n",
       "      <td>Make it quick. 7 lines max.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Serial      Id                                               Text  \\\n",
       "0        0  377801                                     wat is it lmao   \n",
       "1        0  377800                 No risk here platform will be free   \n",
       "2        0  377799  @lordvladin im more confused after I read your...   \n",
       "3        0  377798  has anyone sold or bought a house using crypto...   \n",
       "4        0  377796                            I sent you DM thank you   \n",
       "5        0  377795  Can DM me. I'm out rn but will get back by lat...   \n",
       "6        0  377794  Dequest is an sbt2 layer on web3 gamification ...   \n",
       "7        0  377793  I think dequest focusing on web3 games, as i s...   \n",
       "8        0  377792               but feel free to dm me if using rmrk   \n",
       "9        0  377791                              look into dequest too   \n",
       "10       0  377790  Also if anyone can share what is the defects o...   \n",
       "11       0  377789  Also i was trying to use remark for NFTs to cr...   \n",
       "12       0  377788                            Platform is free to use   \n",
       "13       0  377787  I can also share the platform here with you if...   \n",
       "14       0  377786        I don’t have connections i am working alone   \n",
       "15       0  377785  So the system is ready just working on the con...   \n",
       "16       0  377784    I'm.messing around but share what you are doing   \n",
       "17       0  377783                                 Dude don't mind me   \n",
       "18       0  377782                                             Hahaha   \n",
       "19       0  377781                 I am just excited to talk about it   \n",
       "20       0  377780                                              Sorry   \n",
       "21       0  377779  Other wise working on platform to reward peopl...   \n",
       "22       0  377778                            Sir.  Single para. Pls.   \n",
       "23       0  377777                 Why working on lame, 2d 90th games   \n",
       "24       0  377776                   Okay single text - what it does.   \n",
       "25       0  377775                    And i got an idea while working   \n",
       "26       0  377773                        No it more simple than this   \n",
       "27       0  377772                           If yes then please speak   \n",
       "28       0  377771  Is this “IT” a shitcoin, ponzu or other food f...   \n",
       "29       0  377770                        Make it quick. 7 lines max.   \n",
       "\n",
       "   is_question is_question_using_nltk  \n",
       "0         True                  False  \n",
       "1        False                  False  \n",
       "2        False                  False  \n",
       "3         True                  False  \n",
       "4        False                  False  \n",
       "5         True                  False  \n",
       "6        False                  False  \n",
       "7        False                  False  \n",
       "8        False                  False  \n",
       "9        False                  False  \n",
       "10        True                  False  \n",
       "11        True                  False  \n",
       "12       False                  False  \n",
       "13       False                  False  \n",
       "14       False                  False  \n",
       "15        True                  False  \n",
       "16        True                   True  \n",
       "17       False                  False  \n",
       "18       False                  False  \n",
       "19       False                  False  \n",
       "20       False                  False  \n",
       "21        True                  False  \n",
       "22       False                  False  \n",
       "23        True                  False  \n",
       "24        True                  False  \n",
       "25       False                  False  \n",
       "26       False                  False  \n",
       "27       False                  False  \n",
       "28        True                   True  \n",
       "29       False                  False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8796ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the name of the file\n",
    "def uniquify(path):\n",
    "    filename, extension = os.path.splitext(path)\n",
    "    counter = 1\n",
    "\n",
    "    while os.path.exists(path):\n",
    "        path = filename + \" (\" + str(counter) + \")\" + extension\n",
    "        counter += 1\n",
    "\n",
    "    return path\n",
    "file_name = 'Dataset.xlsx'\n",
    "  \n",
    "# saving the excel\n",
    "df.to_excel(uniquify(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6480fe4b",
   "metadata": {},
   "source": [
    "## Extracting Keywords From Questions For Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b063bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './Dataset_Questions'\n",
    "df_questions = pd.read_excel (f'{PATH}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32550f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ee5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions[\"yake\"] = \"\"\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "\n",
    "for i in tqdm(range(len(df_questions))):\n",
    "    keywords = kw_extractor.extract_keywords(df_questions[\"Text\"][i])\n",
    "    ls = []\n",
    "    for kw in keywords:\n",
    "        str1 = kw[0].split(\" \")\n",
    "        if(kw[1]>0.05) and len(str1) ==1:\n",
    "          ls.append(kw[0])\n",
    "    df_questions.at[i,'yake']  = listToString2(ls)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73cc77",
   "metadata": {},
   "source": [
    "## Saving Result to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the name of the file\n",
    "def uniquify(path):\n",
    "    filename, extension = os.path.splitext(path)\n",
    "    counter = 1\n",
    "\n",
    "    while os.path.exists(path):\n",
    "        path = filename + \" (\" + str(counter) + \")\" + extension\n",
    "        counter += 1\n",
    "\n",
    "    return path\n",
    "file_name = 'Dataset_Questions_With_Keywords.xlsx'\n",
    "  \n",
    "# saving the excel\n",
    "df_questions.to_excel(uniquify(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4974633",
   "metadata": {},
   "source": [
    "## Other Aproaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd355eff",
   "metadata": {},
   "source": [
    "We Can use GSDMM for topic modelling and forming groups of Documents Which have similar theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "# create N-grams\n",
    "def make_n_grams(texts):\n",
    "    bigram = gensim.models.Phrases(texts, min_count=5, threshold=100)  # higher threshold fewer phrases.\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram = gensim.models.Phrases(bigram[texts], threshold=100)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    bigrams_text = [bigram_mod[doc] for doc in texts]\n",
    "    trigrams_text =  [trigram_mod[bigram_mod[doc]] for doc in bigrams_text]\n",
    "    return trigrams_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_reviews = list(sent_to_words(df[\"Text\"]))\n",
    "len(tokens_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bce2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_reviews = make_n_grams(tokens_reviews)\n",
    "len(tokens_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in gensim.parsing.preprocessing.STOPWORDS] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do lemmatization keeping only noun, vb, adv ----------> ADD ADJECTIVES MAYBE???????\n",
    "# because adj is not informative for reviews topic modeling\n",
    "text_lemmatized = lemmatization(tokens_reviews, allowed_postags=['NOUN', 'VERB'])\n",
    "\n",
    "# remove stop words after lemmatization\n",
    "text_lemmatized = remove_stopwords(text_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d63591",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df950144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsdmm import MovieGroupProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k = 40\n",
    "model_alpha = 0.2\n",
    "model_beta = 0.2\n",
    "model_iters = 50\n",
    "mgp = MovieGroupProcess(K=model_k, alpha=model_alpha, beta=model_beta, n_iters=model_iters)\n",
    "\n",
    "vocab = set(x for text in text_lemmatized for x in text)\n",
    "n_terms = len(vocab)\n",
    "model = mgp.fit(text_lemmatized, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6284b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster,sort_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :')\n",
    "\n",
    "for i in range(len(doc_count)):\n",
    "\n",
    "    print(i,\"->\",doc_count[i],end = ', ')\n",
    "\n",
    "# This is for all topics\n",
    "top_index = doc_count.argsort()[::-1]\n",
    "print('\\nMost important clusters (by number of docs inside):', top_index)\n",
    "\n",
    "temp=[]\n",
    "for i in range(len(top_index)):\n",
    "#     print(top_index[i], end=\"#\")\n",
    "    if(doc_count[top_index[i]]==0):\n",
    "        \n",
    "        break\n",
    "    temp.append(top_index[i])\n",
    "#         top_index = np.delete(top_index, i)\n",
    "top_index=np.array(temp)\n",
    "print('\\nMost important clusters (by number of docs inside) without Zeroes:', top_index)\n",
    "\n",
    "# show the top 5 words in term frequency for each cluster \n",
    "print(\"show the top 10 words in term frequency for each cluster\")\n",
    "top_words(mgp.cluster_word_distribution, top_index, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
